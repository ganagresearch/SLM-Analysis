2025-04-24 03:54:28,227 - INFO - --- Starting Security Benchmark Automation (QUANTIZED MODELS) ---
2025-04-24 03:54:28,227 - INFO - Using Python: /workspace/testbedvenv/bin/python
2025-04-24 03:54:28,227 - INFO - Evaluate CLI Script: /workspace/code/model_evaluator/evaluate_cli.py
2025-04-24 03:54:28,227 - INFO - Results Base Directory: /workspace/results/mod/48
2025-04-24 03:54:28,227 - INFO - Limiting samples per benchmark to: 10
2025-04-24 03:54:28,228 - INFO - 
Run 1/1: Model='TinyLlama-1.1B-Chat-v1.0-GPTQ', Benchmark='sevenllm_bench'
2025-04-24 03:54:28,228 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model_path /workspace/models/TinyLlama-1.1B-Chat-v1.0/quantized-gptq-4bit/ --model_type causal --benchmark_name sevenllm_bench --output_dir /workspace/results/mod/48 --model_display_name TinyLlama-1.1B-Chat-v1.0-GPTQ --limit 10
2025-04-24 03:54:30,732 - INFO - Stdout:

2025-04-24 03:54:30,732 - WARNING - Stderr:

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.5 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/workspace/code/model_evaluator/evaluate_cli.py", line 5, in <module>
    import torch
  File "/workspace/testbedvenv/lib/python3.11/site-packages/torch/__init__.py", line 1477, in <module>
    from .functional import *  # noqa: F403
  File "/workspace/testbedvenv/lib/python3.11/site-packages/torch/functional.py", line 9, in <module>
    import torch.nn.functional as F
  File "/workspace/testbedvenv/lib/python3.11/site-packages/torch/nn/__init__.py", line 1, in <module>
    from .modules import *  # noqa: F403
  File "/workspace/testbedvenv/lib/python3.11/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
    from .transformer import TransformerEncoder, TransformerDecoder, \
  File "/workspace/testbedvenv/lib/python3.11/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
/workspace/testbedvenv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)
  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
usage: evaluate_cli.py [-h] --model-path MODEL_PATH
                       [--model-type {causal,encoder}] --benchmark-name
                       {cyberseceval3_mitre,sevenllm_bench,ctibench}
                       --benchmark-path BENCHMARK_PATH
                       [--results-dir RESULTS_DIR] [--device DEVICE]
                       [--max-new-tokens MAX_NEW_TOKENS]
                       [--num-samples NUM_SAMPLES] [--cti-subset CTI_SUBSET]
evaluate_cli.py: error: the following arguments are required: --model-path, --benchmark-name, --benchmark-path

2025-04-24 03:54:30,733 - ERROR - ERROR during: Run 1/1: Model='TinyLlama-1.1B-Chat-v1.0-GPTQ', Benchmark='sevenllm_bench'
  Command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model_path /workspace/models/TinyLlama-1.1B-Chat-v1.0/quantized-gptq-4bit/ --model_type causal --benchmark_name sevenllm_bench --output_dir /workspace/results/mod/48 --model_display_name TinyLlama-1.1B-Chat-v1.0-GPTQ --limit 10
  Return Code: 2
  Stderr:

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.5 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/workspace/code/model_evaluator/evaluate_cli.py", line 5, in <module>
    import torch
  File "/workspace/testbedvenv/lib/python3.11/site-packages/torch/__init__.py", line 1477, in <module>
    from .functional import *  # noqa: F403
  File "/workspace/testbedvenv/lib/python3.11/site-packages/torch/functional.py", line 9, in <module>
    import torch.nn.functional as F
  File "/workspace/testbedvenv/lib/python3.11/site-packages/torch/nn/__init__.py", line 1, in <module>
    from .modules import *  # noqa: F403
  File "/workspace/testbedvenv/lib/python3.11/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
    from .transformer import TransformerEncoder, TransformerDecoder, \
  File "/workspace/testbedvenv/lib/python3.11/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
/workspace/testbedvenv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)
  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
usage: evaluate_cli.py [-h] --model-path MODEL_PATH
                       [--model-type {causal,encoder}] --benchmark-name
                       {cyberseceval3_mitre,sevenllm_bench,ctibench}
                       --benchmark-path BENCHMARK_PATH
                       [--results-dir RESULTS_DIR] [--device DEVICE]
                       [--max-new-tokens MAX_NEW_TOKENS]
                       [--num-samples NUM_SAMPLES] [--cti-subset CTI_SUBSET]
evaluate_cli.py: error: the following arguments are required: --model-path, --benchmark-name, --benchmark-path

  Stdout:

----------------------------------------

2025-04-24 03:54:30,733 - INFO - --- Security Benchmark Automation Finished (QUANTIZED MODELS) ---
