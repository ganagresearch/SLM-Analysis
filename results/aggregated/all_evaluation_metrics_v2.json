[
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "cyberseceval3_mitre",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": null,
    "peak_vram_gpu_mb": 4263.73779296875,
    "peak_ram_system_mb": 4093.01953125,
    "load_time_seconds": 3.7972898483276367,
    "inference_speed_tok_per_sec": 68.09864769400029,
    "avg_inference_time_per_sample_ms": 7496.205853827206,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": "H200",
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T04:38:15",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/quantized-gptq-4bit/",
    "metrics_json_path": "results/mod/cyberseceval3_mitre__20250424-043815_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "sevenllm_bench",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": null,
    "peak_vram_gpu_mb": 4347.0869140625,
    "peak_ram_system_mb": 4070.3671875,
    "load_time_seconds": 3.884247303009033,
    "inference_speed_tok_per_sec": 67.37817441127925,
    "avg_inference_time_per_sample_ms": 3753.8862133026123,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": "H200",
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T04:48:30",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/quantized-gptq-4bit/",
    "metrics_json_path": "results/mod/sevenllm_bench__20250424-044830_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "arc_challenge",
    "task_subset": null,
    "score_metric": "acc",
    "score_value": 0.5708191126279863,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T00:17:01",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/arc_challenge/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-17-01.916049.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/arc_challenge/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-17-01.916049.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "arc_challenge",
    "task_subset": null,
    "score_metric": "acc_stderr",
    "score_value": 0.014464085894870653,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T00:17:01",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/arc_challenge/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-17-01.916049.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/arc_challenge/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-17-01.916049.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "arc_challenge",
    "task_subset": null,
    "score_metric": "acc_norm",
    "score_value": 0.5844709897610921,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T00:17:01",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/arc_challenge/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-17-01.916049.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/arc_challenge/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-17-01.916049.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "arc_challenge",
    "task_subset": null,
    "score_metric": "acc_norm_stderr",
    "score_value": 0.014401366641216384,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T00:17:01",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/arc_challenge/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-17-01.916049.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/arc_challenge/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-17-01.916049.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "gsm8k",
    "task_subset": null,
    "score_metric": "exact_match",
    "score_value": 0.0,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T02:02:04",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/gsm8k/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T02-02-04.225134.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/gsm8k/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T02-02-04.225134.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "gsm8k",
    "task_subset": null,
    "score_metric": "exact_match_stderr",
    "score_value": 0.0,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T02:02:04",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/gsm8k/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T02-02-04.225134.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/gsm8k/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T02-02-04.225134.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "gsm8k",
    "task_subset": null,
    "score_metric": "exact_match",
    "score_value": 0.15314632297194844,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T02:02:04",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/gsm8k/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T02-02-04.225134.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/gsm8k/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T02-02-04.225134.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "gsm8k",
    "task_subset": null,
    "score_metric": "exact_match_stderr",
    "score_value": 0.00991972815279148,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T02:02:04",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/gsm8k/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T02-02-04.225134.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/gsm8k/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T02-02-04.225134.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "hellaswag",
    "task_subset": null,
    "score_metric": "acc",
    "score_value": 0.6482772356104362,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T00:27:52",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/hellaswag/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-27-52.420724.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/hellaswag/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-27-52.420724.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "hellaswag",
    "task_subset": null,
    "score_metric": "acc_stderr",
    "score_value": 0.004765320784902113,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T00:27:52",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/hellaswag/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-27-52.420724.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/hellaswag/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-27-52.420724.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "hellaswag",
    "task_subset": null,
    "score_metric": "acc_norm",
    "score_value": 0.828918542123083,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T00:27:52",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/hellaswag/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-27-52.420724.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/hellaswag/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-27-52.420724.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "hellaswag",
    "task_subset": null,
    "score_metric": "acc_norm_stderr",
    "score_value": 0.0037581050431502194,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T00:27:52",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/hellaswag/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-27-52.420724.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/hellaswag/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-27-52.420724.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "mmlu_elementary_mathematics",
    "task_subset": null,
    "score_metric": "acc",
    "score_value": 0.36507936507936506,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T07:37:16",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/mmlu_elementary_mathematics/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T07-37-16.737632.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/mmlu_elementary_mathematics/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T07-37-16.737632.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "mmlu_elementary_mathematics",
    "task_subset": null,
    "score_metric": "acc_stderr",
    "score_value": 0.024796060602699947,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T07:37:16",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/mmlu_elementary_mathematics/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T07-37-16.737632.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/mmlu_elementary_mathematics/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T07-37-16.737632.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "truthfulqa_mc2",
    "task_subset": null,
    "score_metric": "acc",
    "score_value": 0.5970326737622066,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T07:42:05",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/truthfulqa_mc2/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T07-42-05.486837.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/truthfulqa_mc2/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T07-42-05.486837.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "truthfulqa_mc2",
    "task_subset": null,
    "score_metric": "acc_stderr",
    "score_value": 0.015435512633577935,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T07:42:05",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/truthfulqa_mc2/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T07-42-05.486837.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/truthfulqa_mc2/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T07-42-05.486837.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "winogrande",
    "task_subset": null,
    "score_metric": "acc",
    "score_value": 0.7419100236779794,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T00:29:21",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/winogrande/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-29-21.265544.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/winogrande/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-29-21.265544.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "winogrande",
    "task_subset": null,
    "score_metric": "acc_stderr",
    "score_value": 0.01229827883397239,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T00:29:21",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/nlp/bare/Mistral-7B-Instruct-v0.3/winogrande/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-29-21.265544.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Mistral-7B-Instruct-v0.3/winogrande/results.json/__workspace__models__Mistral-7B-Instruct-v0.3__/results_2025-04-23T00-29-21.265544.json"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-mcq",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": 27755.52734375,
    "peak_ram_system_mb": 1869.5390625,
    "load_time_seconds": 75.1007239818573,
    "inference_speed_tok_per_sec": 12.534515093871523,
    "avg_inference_time_per_sample_ms": 708.4438395500183,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T20:20:49",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/bare/ctibench_cti-mcq__20250422-202049_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-rcm",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": 27976.64599609375,
    "peak_ram_system_mb": 1857.2265625,
    "load_time_seconds": 74.21410274505615,
    "inference_speed_tok_per_sec": 18.12348968616266,
    "avg_inference_time_per_sample_ms": 10666.268105506897,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T21:03:28",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/bare/ctibench_cti-rcm__20250422-210328_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-vsp",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": 28113.490234375,
    "peak_ram_system_mb": 1867.671875,
    "load_time_seconds": 25.49985957145691,
    "inference_speed_tok_per_sec": 17.173704791280787,
    "avg_inference_time_per_sample_ms": 22908.8600730896,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T20:23:52",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/bare/ctibench_cti-vsp__20250422-202352_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "cyberseceval3_mitre",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": 27941.5234375,
    "peak_ram_system_mb": 1858.72265625,
    "load_time_seconds": 73.30368781089783,
    "inference_speed_tok_per_sec": 17.517999486081322,
    "avg_inference_time_per_sample_ms": 29110.799059455778,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T19:12:51",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/bare/cyberseceval3_mitre__20250422-191251_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3",
    "parameters": "7B",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "sevenllm_bench",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 27.004,
    "peak_vram_gpu_mb": 28117.02880859375,
    "peak_ram_system_mb": 1851.015625,
    "load_time_seconds": 68.78797459602356,
    "inference_speed_tok_per_sec": 17.227226097459905,
    "avg_inference_time_per_sample_ms": 14798.668024539948,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T19:54:13",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "metrics_json_path": "results/bare/sevenllm_bench__20250422-195413_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3-GPTQ",
    "parameters": "7B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-mcq",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 3.886,
    "peak_vram_gpu_mb": 6126.51953125,
    "peak_ram_system_mb": 3511.76171875,
    "load_time_seconds": 49.26835560798645,
    "inference_speed_tok_per_sec": 93.77482747898922,
    "avg_inference_time_per_sample_ms": 1665.2656602859497,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T13:14:09",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3-GPTQ",
    "metrics_json_path": "results/mod/ctibench_cti-mcq_Mistral-7B-Instruct-v0.3-GPTQ_20250424-131409_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3-GPTQ",
    "parameters": "7B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-rcm",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 3.886,
    "peak_vram_gpu_mb": 9125.1123046875,
    "peak_ram_system_mb": 3597.15234375,
    "load_time_seconds": 16.485604524612427,
    "inference_speed_tok_per_sec": 82.83744745459103,
    "avg_inference_time_per_sample_ms": 3694.4643926620483,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T13:30:11",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3-GPTQ",
    "metrics_json_path": "results/mod/ctibench_cti-rcm_Mistral-7B-Instruct-v0.3-GPTQ_20250424-133011_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3-GPTQ",
    "parameters": "7B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-vsp",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 3.886,
    "peak_vram_gpu_mb": 11316.9501953125,
    "peak_ram_system_mb": 3529.65234375,
    "load_time_seconds": 17.680996417999268,
    "inference_speed_tok_per_sec": 73.90778235196053,
    "avg_inference_time_per_sample_ms": 6878.166058063507,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T13:18:06",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3-GPTQ",
    "metrics_json_path": "results/mod/ctibench_cti-vsp_Mistral-7B-Instruct-v0.3-GPTQ_20250424-131806_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3-GPTQ",
    "parameters": "7B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "cyberseceval3_mitre",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 3.886,
    "peak_vram_gpu_mb": 8498.654296875,
    "peak_ram_system_mb": 4106.37890625,
    "load_time_seconds": 51.40504050254822,
    "inference_speed_tok_per_sec": 83.60549446898082,
    "avg_inference_time_per_sample_ms": 6123.851758462411,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T12:52:16",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3-GPTQ",
    "metrics_json_path": "results/mod/cyberseceval3_mitre_Mistral-7B-Instruct-v0.3-GPTQ_20250424-125216_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.3-GPTQ",
    "parameters": "7B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "sevenllm_bench",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 3.886,
    "peak_vram_gpu_mb": 10656.2705078125,
    "peak_ram_system_mb": 3509.16015625,
    "load_time_seconds": 18.11532163619995,
    "inference_speed_tok_per_sec": 73.36996740670968,
    "avg_inference_time_per_sample_ms": 6949.164869785309,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T13:01:42",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3-GPTQ",
    "metrics_json_path": "results/mod/sevenllm_bench_Mistral-7B-Instruct-v0.3-GPTQ_20250424-130142_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Phi-3-mini-4k-instruct-GPTQ",
    "parameters": "3.8B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-mcq",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 2.127,
    "peak_vram_gpu_mb": 2174.7666015625,
    "peak_ram_system_mb": 1977.734375,
    "load_time_seconds": 14.670984268188477,
    "inference_speed_tok_per_sec": 0.0,
    "avg_inference_time_per_sample_ms": 0.0,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T11:43:01",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct-GPTQ",
    "metrics_json_path": "results/mod/ctibench_cti-mcq_Phi-3-mini-4k-instruct-GPTQ_20250424-114301_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Phi-3-mini-4k-instruct-GPTQ",
    "parameters": "3.8B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-mcq",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 2.127,
    "peak_vram_gpu_mb": 2174.7666015625,
    "peak_ram_system_mb": 1972.51171875,
    "load_time_seconds": 14.208012104034424,
    "inference_speed_tok_per_sec": 0.0,
    "avg_inference_time_per_sample_ms": 0.0,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T11:49:43",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct-GPTQ",
    "metrics_json_path": "results/mod/ctibench_cti-mcq_Phi-3-mini-4k-instruct-GPTQ_20250424-114943_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Phi-3-mini-4k-instruct-GPTQ",
    "parameters": "3.8B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-mcq",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 2.127,
    "peak_vram_gpu_mb": 7797.2158203125,
    "peak_ram_system_mb": 2458.23046875,
    "load_time_seconds": 14.463181734085083,
    "inference_speed_tok_per_sec": 48.30978123843526,
    "avg_inference_time_per_sample_ms": 41.3994836807251,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T12:36:49",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct-GPTQ",
    "metrics_json_path": "results/mod/ctibench_cti-mcq_Phi-3-mini-4k-instruct-GPTQ_20250424-123649_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Phi-3-mini-4k-instruct-GPTQ",
    "parameters": "3.8B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-rcm",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 2.127,
    "peak_vram_gpu_mb": 2174.7802734375,
    "peak_ram_system_mb": 1961.67578125,
    "load_time_seconds": 28.427633047103882,
    "inference_speed_tok_per_sec": 0.0,
    "avg_inference_time_per_sample_ms": 0.0,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T11:44:36",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct-GPTQ",
    "metrics_json_path": "results/mod/ctibench_cti-rcm_Phi-3-mini-4k-instruct-GPTQ_20250424-114436_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Phi-3-mini-4k-instruct-GPTQ",
    "parameters": "3.8B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-rcm",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 2.127,
    "peak_vram_gpu_mb": 20517.88671875,
    "peak_ram_system_mb": 2333.73828125,
    "load_time_seconds": 14.982768774032593,
    "inference_speed_tok_per_sec": 112.35590069861071,
    "avg_inference_time_per_sample_ms": 2489.054853916168,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T12:45:34",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct-GPTQ",
    "metrics_json_path": "results/mod/ctibench_cti-rcm_Phi-3-mini-4k-instruct-GPTQ_20250424-124534_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Phi-3-mini-4k-instruct-GPTQ",
    "parameters": "3.8B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-vsp",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 2.127,
    "peak_vram_gpu_mb": 2174.7900390625,
    "peak_ram_system_mb": 1957.45703125,
    "load_time_seconds": 18.83029794692993,
    "inference_speed_tok_per_sec": 0.0,
    "avg_inference_time_per_sample_ms": 0.0,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T11:43:39",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct-GPTQ",
    "metrics_json_path": "results/mod/ctibench_cti-vsp_Phi-3-mini-4k-instruct-GPTQ_20250424-114339_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Phi-3-mini-4k-instruct-GPTQ",
    "parameters": "3.8B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-vsp",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 2.127,
    "peak_vram_gpu_mb": 28552.69189453125,
    "peak_ram_system_mb": 2080.17578125,
    "load_time_seconds": 14.294179201126099,
    "inference_speed_tok_per_sec": 115.83080445744557,
    "avg_inference_time_per_sample_ms": 4415.578415393829,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T12:37:29",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct-GPTQ",
    "metrics_json_path": "results/mod/ctibench_cti-vsp_Phi-3-mini-4k-instruct-GPTQ_20250424-123729_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Phi-3-mini-4k-instruct-GPTQ",
    "parameters": "3.8B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "cyberseceval3_mitre",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 2.127,
    "peak_vram_gpu_mb": 15448.56494140625,
    "peak_ram_system_mb": 1748.4375,
    "load_time_seconds": 15.088515043258667,
    "inference_speed_tok_per_sec": 138.6920674385276,
    "avg_inference_time_per_sample_ms": 3690.474268830853,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T12:23:20",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct-GPTQ",
    "metrics_json_path": "results/mod/cyberseceval3_mitre_Phi-3-mini-4k-instruct-GPTQ_20250424-122320_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Phi-3-mini-4k-instruct-GPTQ",
    "parameters": "3.8B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "sevenllm_bench",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 2.127,
    "peak_vram_gpu_mb": 2174.7900390625,
    "peak_ram_system_mb": 1972.19140625,
    "load_time_seconds": 13.814217329025269,
    "inference_speed_tok_per_sec": 0.0,
    "avg_inference_time_per_sample_ms": 0.0,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T11:42:29",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct-GPTQ",
    "metrics_json_path": "results/mod/sevenllm_bench_Phi-3-mini-4k-instruct-GPTQ_20250424-114229_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Phi-3-mini-4k-instruct-GPTQ",
    "parameters": "3.8B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "sevenllm_bench",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 2.127,
    "peak_vram_gpu_mb": 2174.7900390625,
    "peak_ram_system_mb": 1940.453125,
    "load_time_seconds": 14.571175575256348,
    "inference_speed_tok_per_sec": 0.0,
    "avg_inference_time_per_sample_ms": 0.0,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T11:49:11",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct-GPTQ",
    "metrics_json_path": "results/mod/sevenllm_bench_Phi-3-mini-4k-instruct-GPTQ_20250424-114911_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "Phi-3-mini-4k-instruct-GPTQ",
    "parameters": "3.8B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "sevenllm_bench",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 2.127,
    "peak_vram_gpu_mb": 26297.55419921875,
    "peak_ram_system_mb": 2359.78125,
    "load_time_seconds": 15.400579929351807,
    "inference_speed_tok_per_sec": 116.15881242677162,
    "avg_inference_time_per_sample_ms": 4405.434157848358,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T12:28:54",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct-GPTQ",
    "metrics_json_path": "results/mod/sevenllm_bench_Phi-3-mini-4k-instruct-GPTQ_20250424-122854_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "cyberseceval3_mitre",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": null,
    "peak_vram_gpu_mb": 826.7421875,
    "peak_ram_system_mb": 1775.9453125,
    "load_time_seconds": 2.00423002243042,
    "inference_speed_tok_per_sec": 100.35952925988187,
    "avg_inference_time_per_sample_ms": 4861.533709514288,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": "A40",
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T04:24:53",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/quantized-gptq-4bit/",
    "metrics_json_path": "results/mod/cyberseceval3_mitre__20250424-042453_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "sevenllm_bench",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": null,
    "peak_vram_gpu_mb": 817.59033203125,
    "peak_ram_system_mb": 1828.15625,
    "load_time_seconds": 2.290864944458008,
    "inference_speed_tok_per_sec": 91.98322456636693,
    "avg_inference_time_per_sample_ms": 2509.153175354004,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": "A40",
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T04:08:59",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/quantized-gptq-4bit/",
    "metrics_json_path": "results/mod/sevenllm_bench__20250424-040859_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "sevenllm_bench",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": null,
    "peak_vram_gpu_mb": 861.32177734375,
    "peak_ram_system_mb": 1786.3046875,
    "load_time_seconds": 1.9934163093566895,
    "inference_speed_tok_per_sec": 99.79107742640835,
    "avg_inference_time_per_sample_ms": 3377.255849838257,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": "A40",
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T04:31:32",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/quantized-gptq-4bit/",
    "metrics_json_path": "results/mod/sevenllm_bench__20250424-043132_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "arc_challenge",
    "task_subset": null,
    "score_metric": "acc",
    "score_value": 0.2986348122866894,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:04:51",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/arc_challenge/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-04-51.952031.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/arc_challenge/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-04-51.952031.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "arc_challenge",
    "task_subset": null,
    "score_metric": "acc_stderr",
    "score_value": 0.013374078615068742,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:04:51",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/arc_challenge/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-04-51.952031.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/arc_challenge/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-04-51.952031.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "arc_challenge",
    "task_subset": null,
    "score_metric": "acc_norm",
    "score_value": 0.32764505119453924,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:04:51",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/arc_challenge/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-04-51.952031.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/arc_challenge/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-04-51.952031.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "arc_challenge",
    "task_subset": null,
    "score_metric": "acc_norm_stderr",
    "score_value": 0.013715847940719337,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:04:51",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/arc_challenge/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-04-51.952031.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/arc_challenge/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-04-51.952031.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "gsm8k",
    "task_subset": null,
    "score_metric": "exact_match",
    "score_value": 0.0,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:16:22",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/gsm8k/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-16-22.064028.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/gsm8k/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-16-22.064028.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "gsm8k",
    "task_subset": null,
    "score_metric": "exact_match_stderr",
    "score_value": 0.0,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:16:22",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/gsm8k/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-16-22.064028.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/gsm8k/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-16-22.064028.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "gsm8k",
    "task_subset": null,
    "score_metric": "exact_match",
    "score_value": 0.02577710386656558,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:16:22",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/gsm8k/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-16-22.064028.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/gsm8k/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-16-22.064028.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "gsm8k",
    "task_subset": null,
    "score_metric": "exact_match_stderr",
    "score_value": 0.004365042953621817,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:16:22",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/gsm8k/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-16-22.064028.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/gsm8k/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-16-22.064028.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "hellaswag",
    "task_subset": null,
    "score_metric": "acc",
    "score_value": 0.46594303923521213,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:08:32",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/hellaswag/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-08-32.236904.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/hellaswag/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-08-32.236904.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "hellaswag",
    "task_subset": null,
    "score_metric": "acc_stderr",
    "score_value": 0.004978192893406282,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:08:32",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/hellaswag/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-08-32.236904.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/hellaswag/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-08-32.236904.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "hellaswag",
    "task_subset": null,
    "score_metric": "acc_norm",
    "score_value": 0.6041625174268074,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:08:32",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/hellaswag/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-08-32.236904.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/hellaswag/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-08-32.236904.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "hellaswag",
    "task_subset": null,
    "score_metric": "acc_norm_stderr",
    "score_value": 0.004880303863138489,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:08:32",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/hellaswag/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-08-32.236904.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/hellaswag/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-08-32.236904.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "mmlu_elementary_mathematics",
    "task_subset": null,
    "score_metric": "acc",
    "score_value": 0.26455026455026454,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T07:27:50",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/mmlu_elementary_mathematics/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-23T07-27-50.218214.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/mmlu_elementary_mathematics/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-23T07-27-50.218214.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "mmlu_elementary_mathematics",
    "task_subset": null,
    "score_metric": "acc_stderr",
    "score_value": 0.022717467897708604,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T07:27:50",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/mmlu_elementary_mathematics/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-23T07-27-50.218214.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/mmlu_elementary_mathematics/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-23T07-27-50.218214.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "truthfulqa_mc2",
    "task_subset": null,
    "score_metric": "acc",
    "score_value": 0.3783627061628494,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T07:29:50",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/truthfulqa_mc2/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-23T07-29-50.714862.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/truthfulqa_mc2/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-23T07-29-50.714862.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "truthfulqa_mc2",
    "task_subset": null,
    "score_metric": "acc_stderr",
    "score_value": 0.01396592668040239,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T07:29:50",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/truthfulqa_mc2/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-23T07-29-50.714862.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/truthfulqa_mc2/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-23T07-29-50.714862.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "winogrande",
    "task_subset": null,
    "score_metric": "acc",
    "score_value": 0.6053670086819258,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:09:48",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/winogrande/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-09-48.913750.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/winogrande/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-09-48.913750.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "winogrande",
    "task_subset": null,
    "score_metric": "acc_stderr",
    "score_value": 0.013736915172371885,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:09:48",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/winogrande/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-09-48.913750.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/TinyLlama-1.1B-Chat-v1.0/winogrande/results.json/__workspace__models__TinyLlama-1.1B-Chat-v1.0__/results_2025-04-22T23-09-48.913750.json"
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-mcq",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": 4235.52392578125,
    "peak_ram_system_mb": 1706.55859375,
    "load_time_seconds": 27.62544846534729,
    "inference_speed_tok_per_sec": 59.6831179036133,
    "avg_inference_time_per_sample_ms": 626.9779682159424,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T17:43:49",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/bare/ctibench_cti-mcq__20250422-174349_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-rcm",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": 4301.64306640625,
    "peak_ram_system_mb": 1727.91015625,
    "load_time_seconds": 8.493966817855835,
    "inference_speed_tok_per_sec": 64.2126295763086,
    "avg_inference_time_per_sample_ms": 4765.106210708618,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T17:54:38",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/bare/ctibench_cti-rcm__20250422-175438_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-vsp",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": 4345.7431640625,
    "peak_ram_system_mb": 1735.8671875,
    "load_time_seconds": 8.537639379501343,
    "inference_speed_tok_per_sec": 68.29002737186609,
    "avg_inference_time_per_sample_ms": 4894.418890476227,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T17:45:51",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/bare/ctibench_cti-vsp__20250422-174551_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "cyberseceval3_mitre",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": 4275.90673828125,
    "peak_ram_system_mb": 1654.4375,
    "load_time_seconds": 28.046671628952026,
    "inference_speed_tok_per_sec": 67.5812629580115,
    "avg_inference_time_per_sample_ms": 7532.404107812011,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T17:21:06",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/bare/cyberseceval3_mitre__20250422-172106_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0",
    "parameters": "1.1B",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "sevenllm_bench",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 3.263,
    "peak_vram_gpu_mb": 4345.23095703125,
    "peak_ram_system_mb": 1707.9453125,
    "load_time_seconds": 30.071579217910767,
    "inference_speed_tok_per_sec": 68.62372464731872,
    "avg_inference_time_per_sample_ms": 5938.616740703583,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T17:32:36",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/",
    "metrics_json_path": "results/bare/sevenllm_bench__20250422-173236_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0-GPTQ",
    "parameters": "1.1B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-mcq",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 0.719,
    "peak_vram_gpu_mb": 817.6396484375,
    "peak_ram_system_mb": 1680.19921875,
    "load_time_seconds": 13.241381168365479,
    "inference_speed_tok_per_sec": 22.2459739736972,
    "avg_inference_time_per_sample_ms": 1834.9387645721436,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T08:38:12",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0-GPTQ",
    "metrics_json_path": "results/mod/ctibench_cti-mcq_TinyLlama-1.1B-Chat-v1.0-GPTQ_20250424-083812_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0-GPTQ",
    "parameters": "1.1B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-rcm",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 0.719,
    "peak_vram_gpu_mb": 837.61669921875,
    "peak_ram_system_mb": 1745.046875,
    "load_time_seconds": 13.308476448059082,
    "inference_speed_tok_per_sec": 22.964910579054,
    "avg_inference_time_per_sample_ms": 12469.458525180817,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T09:19:24",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0-GPTQ",
    "metrics_json_path": "results/mod/ctibench_cti-rcm_TinyLlama-1.1B-Chat-v1.0-GPTQ_20250424-091924_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0-GPTQ",
    "parameters": "1.1B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-vsp",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 0.719,
    "peak_vram_gpu_mb": 852.435546875,
    "peak_ram_system_mb": 1741.4296875,
    "load_time_seconds": 6.265382766723633,
    "inference_speed_tok_per_sec": 22.988657065542814,
    "avg_inference_time_per_sample_ms": 21897.75586128235,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T08:41:59",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0-GPTQ",
    "metrics_json_path": "results/mod/ctibench_cti-vsp_TinyLlama-1.1B-Chat-v1.0-GPTQ_20250424-084159_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0-GPTQ",
    "parameters": "1.1B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "cyberseceval3_mitre",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 0.719,
    "peak_vram_gpu_mb": 827.70751953125,
    "peak_ram_system_mb": 1720.40234375,
    "load_time_seconds": 6.248593330383301,
    "inference_speed_tok_per_sec": 22.99509581355794,
    "avg_inference_time_per_sample_ms": 21298.15376246417,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T07:43:17",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0-GPTQ",
    "metrics_json_path": "results/mod/cyberseceval3_mitre_TinyLlama-1.1B-Chat-v1.0-GPTQ_20250424-074317_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "TinyLlama-1.1B-Chat-v1.0-GPTQ",
    "parameters": "1.1B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "sevenllm_bench",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 0.719,
    "peak_vram_gpu_mb": 852.4365234375,
    "peak_ram_system_mb": 1743.9140625,
    "load_time_seconds": 13.780585289001465,
    "inference_speed_tok_per_sec": 22.969539248518444,
    "avg_inference_time_per_sample_ms": 14549.26876783371,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T08:12:54",
    "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0-GPTQ",
    "metrics_json_path": "results/mod/sevenllm_bench_TinyLlama-1.1B-Chat-v1.0-GPTQ_20250424-081254_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "electra-small-discriminator",
    "parameters": "14M",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-mcq",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 0.152,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": 4.706421613693237,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T21:24:17",
    "model_path": "/workspace/models/electra-small-discriminator/",
    "metrics_json_path": "results/bare/ctibench_cti-mcq__20250422-212417_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "electra-small-discriminator",
    "parameters": "14M",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-rcm",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 0.152,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": 4.392098903656006,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T21:25:23",
    "model_path": "/workspace/models/electra-small-discriminator/",
    "metrics_json_path": "results/bare/ctibench_cti-rcm__20250422-212523_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "electra-small-discriminator",
    "parameters": "14M",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-vsp",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 0.152,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": 4.432291507720947,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T21:24:50",
    "model_path": "/workspace/models/electra-small-discriminator/",
    "metrics_json_path": "results/bare/ctibench_cti-vsp__20250422-212450_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "electra-small-discriminator",
    "parameters": "14M",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "cyberseceval3_mitre",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 0.152,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": 5.257962942123413,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T21:23:13",
    "model_path": "/workspace/models/electra-small-discriminator/",
    "metrics_json_path": "results/bare/cyberseceval3_mitre__20250422-212313_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "electra-small-discriminator",
    "parameters": "14M",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "sevenllm_bench",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 0.152,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": 4.669155597686768,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T21:23:44",
    "model_path": "/workspace/models/electra-small-discriminator/",
    "metrics_json_path": "results/bare/sevenllm_bench__20250422-212344_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "cyberseceval3_mitre",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": null,
    "peak_vram_gpu_mb": 2270.77490234375,
    "peak_ram_system_mb": 1969.94140625,
    "load_time_seconds": 2.4265379905700684,
    "inference_speed_tok_per_sec": 0.0,
    "avg_inference_time_per_sample_ms": 0.0,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": "H200",
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T04:37:39",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/quantized-gptq-4bit/",
    "metrics_json_path": "results/mod/cyberseceval3_mitre__20250424-043739_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "AutoGPTQ-4bit",
    "benchmark_suite": "Security",
    "benchmark_name": "sevenllm_bench",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": null,
    "peak_vram_gpu_mb": 2270.79052734375,
    "peak_ram_system_mb": 1983.17578125,
    "load_time_seconds": 2.4482619762420654,
    "inference_speed_tok_per_sec": 0.0,
    "avg_inference_time_per_sample_ms": 0.0,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": "H200",
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-24T04:37:45",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/quantized-gptq-4bit/",
    "metrics_json_path": "results/mod/sevenllm_bench__20250424-043745_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "arc_challenge",
    "task_subset": null,
    "score_metric": "acc",
    "score_value": 0.5418088737201365,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:18:19",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/arc_challenge/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-18-19.250037.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/arc_challenge/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-18-19.250037.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "arc_challenge",
    "task_subset": null,
    "score_metric": "acc_stderr",
    "score_value": 0.014560220308714695,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:18:19",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/arc_challenge/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-18-19.250037.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/arc_challenge/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-18-19.250037.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "arc_challenge",
    "task_subset": null,
    "score_metric": "acc_norm",
    "score_value": 0.5656996587030717,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:18:19",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/arc_challenge/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-18-19.250037.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/arc_challenge/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-18-19.250037.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "arc_challenge",
    "task_subset": null,
    "score_metric": "acc_norm_stderr",
    "score_value": 0.014484703048857359,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:18:19",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/arc_challenge/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-18-19.250037.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/arc_challenge/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-18-19.250037.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "gsm8k",
    "task_subset": null,
    "score_metric": "exact_match",
    "score_value": 0.13191811978771797,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T00:13:58",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/gsm8k/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T00-13-58.065164.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/gsm8k/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T00-13-58.065164.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "gsm8k",
    "task_subset": null,
    "score_metric": "exact_match_stderr",
    "score_value": 0.009321265253857515,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T00:13:58",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/gsm8k/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T00-13-58.065164.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/gsm8k/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T00-13-58.065164.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "gsm8k",
    "task_subset": null,
    "score_metric": "exact_match",
    "score_value": 0.6914329037149356,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T00:13:58",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/gsm8k/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T00-13-58.065164.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/gsm8k/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T00-13-58.065164.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "gsm8k",
    "task_subset": null,
    "score_metric": "exact_match_stderr",
    "score_value": 0.0127230760498159,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T00:13:58",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/gsm8k/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T00-13-58.065164.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/gsm8k/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T00-13-58.065164.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "hellaswag",
    "task_subset": null,
    "score_metric": "acc",
    "score_value": 0.5899223262298346,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:26:08",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/hellaswag/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-26-08.775893.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/hellaswag/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-26-08.775893.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "hellaswag",
    "task_subset": null,
    "score_metric": "acc_stderr",
    "score_value": 0.0049084231471620355,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:26:08",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/hellaswag/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-26-08.775893.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/hellaswag/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-26-08.775893.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "hellaswag",
    "task_subset": null,
    "score_metric": "acc_norm",
    "score_value": 0.7744473212507469,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:26:08",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/hellaswag/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-26-08.775893.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/hellaswag/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-26-08.775893.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "hellaswag",
    "task_subset": null,
    "score_metric": "acc_norm_stderr",
    "score_value": 0.004170916082572454,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:26:08",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/hellaswag/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-26-08.775893.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/hellaswag/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-26-08.775893.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "mmlu_elementary_mathematics",
    "task_subset": null,
    "score_metric": "acc",
    "score_value": 0.5291005291005291,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T07:31:31",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/mmlu_elementary_mathematics/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T07-31-31.665463.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/mmlu_elementary_mathematics/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T07-31-31.665463.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "mmlu_elementary_mathematics",
    "task_subset": null,
    "score_metric": "acc_stderr",
    "score_value": 0.025707658614154964,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T07:31:31",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/mmlu_elementary_mathematics/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T07-31-31.665463.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/mmlu_elementary_mathematics/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T07-31-31.665463.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "truthfulqa_mc2",
    "task_subset": null,
    "score_metric": "acc",
    "score_value": 0.5445730867707153,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T07:35:17",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/truthfulqa_mc2/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T07-35-17.757403.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/truthfulqa_mc2/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T07-35-17.757403.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "truthfulqa_mc2",
    "task_subset": null,
    "score_metric": "acc_stderr",
    "score_value": 0.015123794011077888,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-23T07:35:17",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/truthfulqa_mc2/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T07-35-17.757403.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/truthfulqa_mc2/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-23T07-35-17.757403.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "winogrande",
    "task_subset": null,
    "score_metric": "acc",
    "score_value": 0.7348066298342542,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:27:26",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/winogrande/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-27-26.786912.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/winogrande/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-27-26.786912.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "NLP",
    "benchmark_name": "winogrande",
    "task_subset": null,
    "score_metric": "acc_stderr",
    "score_value": 0.01240654946619286,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": null,
    "peak_ram_system_mb": null,
    "load_time_seconds": null,
    "inference_speed_tok_per_sec": null,
    "avg_inference_time_per_sample_ms": null,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "lm-evaluation-harness",
    "timestamp": "2025-04-22T23:27:26",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/nlp/bare/Phi-3-mini-4k-instruct/winogrande/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-27-26.786912.json",
    "outputs_json_path": null,
    "score_source_file": "results/nlp/bare/Phi-3-mini-4k-instruct/winogrande/results.json/__workspace__models__Phi-3-mini-4k-instruct__/results_2025-04-22T23-27-26.786912.json"
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-mcq",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": 14943.65478515625,
    "peak_ram_system_mb": 1305.0625,
    "load_time_seconds": 44.40160298347473,
    "inference_speed_tok_per_sec": 11.51227313147309,
    "avg_inference_time_per_sample_ms": 173.72763633728027,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T18:41:25",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/bare/ctibench_cti-mcq__20250422-184125_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-rcm",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": 15760.5283203125,
    "peak_ram_system_mb": 1312.08203125,
    "load_time_seconds": 43.33600974082947,
    "inference_speed_tok_per_sec": 32.06182222102449,
    "avg_inference_time_per_sample_ms": 3965.1520466804504,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T19:04:48",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/bare/ctibench_cti-rcm__20250422-190448_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "ctibench",
    "task_subset": "cti-vsp",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": 16347.72412109375,
    "peak_ram_system_mb": 1337.7109375,
    "load_time_seconds": 15.276558876037598,
    "inference_speed_tok_per_sec": 30.60501951933152,
    "avg_inference_time_per_sample_ms": 12507.4254488945,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T18:42:59",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/bare/ctibench_cti-vsp__20250422-184259_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "cyberseceval3_mitre",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": 15443.9482421875,
    "peak_ram_system_mb": 1305.140625,
    "load_time_seconds": 44.87863278388977,
    "inference_speed_tok_per_sec": 31.275605076477014,
    "avg_inference_time_per_sample_ms": 13057.5480490555,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T18:03:14",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/bare/cyberseceval3_mitre__20250422-180314_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  },
  {
    "model_name": "phi-3-mini-4k-instruct",
    "parameters": "3.8B",
    "quantization_status": "baseline",
    "benchmark_suite": "Security",
    "benchmark_name": "sevenllm_bench",
    "task_subset": "full",
    "score_metric": null,
    "score_value": null,
    "score_stderr": null,
    "model_size_disk_gb": 49.831,
    "peak_vram_gpu_mb": 16362.3857421875,
    "peak_ram_system_mb": 1307.94921875,
    "load_time_seconds": 64.6725127696991,
    "inference_speed_tok_per_sec": 30.752542152627363,
    "avg_inference_time_per_sample_ms": 9580.346188545227,
    "num_fewshot": 0,
    "eval_hardware": "A40",
    "quant_hardware": null,
    "evaluation_script": "evaluate_cli.py",
    "timestamp": "2025-04-22T18:23:36",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "metrics_json_path": "results/bare/sevenllm_bench__20250422-182336_metrics.json",
    "outputs_json_path": null,
    "score_source_file": null
  }
]