[
    {
        "model_name": "Mistral-7B-Instruct-v0.3",
        "benchmark_name": "sevenllm_bench",
        "timestamp_str": "20250422-195413",
        "outputs_file": "/workspace/results/bare/48/sevenllm_bench__20250422-195413_outputs.json",
        "total_items_in_output": 100,
        "items_with_ground_truth": 100,
        "items_missing_ground_truth": 0,
        "refusal_count": 0,
        "valid_processed_count": 100,
        "exact_match_count": 0,
        "refusal_rate": 0.0,
        "exact_match_accuracy": 0.0,
        "average_rouge1_f1": 0.4226,
        "average_rouge2_f1": 0.212,
        "average_rougeL_f1": 0.3019
    },
    {
        "model_name": "Phi-3-mini-4k-instruct",
        "benchmark_name": "sevenllm_bench",
        "timestamp_str": "20250422-182336",
        "outputs_file": "/workspace/results/bare/48/sevenllm_bench__20250422-182336_outputs.json",
        "total_items_in_output": 100,
        "items_with_ground_truth": 100,
        "items_missing_ground_truth": 0,
        "refusal_count": 0,
        "valid_processed_count": 100,
        "exact_match_count": 0,
        "refusal_rate": 0.0,
        "exact_match_accuracy": 0.0,
        "average_rouge1_f1": 0.3817,
        "average_rouge2_f1": 0.1943,
        "average_rougeL_f1": 0.2841
    },
    {
        "model_name": "TinyLlama-1.1B-Chat-v1.0",
        "benchmark_name": "sevenllm_bench",
        "timestamp_str": "20250422-173236",
        "outputs_file": "/workspace/results/bare/48/sevenllm_bench__20250422-173236_outputs.json",
        "total_items_in_output": 100,
        "items_with_ground_truth": 100,
        "items_missing_ground_truth": 0,
        "refusal_count": 0,
        "valid_processed_count": 100,
        "exact_match_count": 0,
        "refusal_rate": 0.0,
        "exact_match_accuracy": 0.0,
        "average_rouge1_f1": 0.1073,
        "average_rouge2_f1": 0.0257,
        "average_rougeL_f1": 0.0713
    }
]