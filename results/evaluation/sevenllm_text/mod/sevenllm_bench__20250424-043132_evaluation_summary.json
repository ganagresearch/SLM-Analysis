{
    "model_name": "quantized-gptq-4bit",
    "benchmark_name": "sevenllm_bench",
    "timestamp_str": "20250424-043132",
    "outputs_file": "results/mod/48/sevenllm_bench__20250424-043132_outputs.json",
    "metrics_file": "results/mod/48/sevenllm_bench__20250424-043132_metrics.json",
    "run_args": {
        "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/quantized-gptq-4bit/",
        "model_type": "causal",
        "benchmark_name": "sevenllm_bench",
        "benchmark_path": "/workspace/calibration_data/sevenllm_instruct_subset_manual/",
        "results_dir": "/workspace/results/mod/48",
        "device": "cuda",
        "max_new_tokens": 512,
        "num_samples": 100,
        "cti_subset": null
    },
    "total_items_in_output": 100,
    "items_with_ground_truth": 100,
    "items_missing_ground_truth": 0,
    "refusal_count": 0,
    "valid_processed_count": 100,
    "exact_match_count": 0,
    "refusal_rate": 0.0,
    "exact_match_accuracy": 0.0,
    "average_rouge1_f1": 0.0,
    "average_rouge2_f1": 0.0,
    "average_rougeL_f1": 0.0
}