[
    {
        "model_name": "quantized-gptq-4bit",
        "benchmark_name": "sevenllm_bench",
        "timestamp_str": "20250424-040859",
        "outputs_file": "results/mod/48/sevenllm_bench__20250424-040859_outputs.json",
        "metrics_file": "results/mod/48/sevenllm_bench__20250424-040859_metrics.json",
        "run_args": {
            "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/quantized-gptq-4bit/",
            "model_type": "causal",
            "benchmark_name": "sevenllm_bench",
            "benchmark_path": "/workspace/datasets/SEVENLLM_instruct_HF",
            "results_dir": "/workspace/results/mod/48",
            "device": "cuda",
            "max_new_tokens": 256,
            "num_samples": 10,
            "cti_subset": null
        },
        "total_items_in_output": 10,
        "items_with_ground_truth": 10,
        "items_missing_ground_truth": 0,
        "refusal_count": 0,
        "valid_processed_count": 10,
        "exact_match_count": 0,
        "refusal_rate": 0.0,
        "exact_match_accuracy": 0.0,
        "average_rouge1_f1": 0.0,
        "average_rouge2_f1": 0.0,
        "average_rougeL_f1": 0.0
    },
    {
        "model_name": "quantized-gptq-4bit",
        "benchmark_name": "sevenllm_bench",
        "timestamp_str": "20250424-043132",
        "outputs_file": "results/mod/48/sevenllm_bench__20250424-043132_outputs.json",
        "metrics_file": "results/mod/48/sevenllm_bench__20250424-043132_metrics.json",
        "run_args": {
            "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0/quantized-gptq-4bit/",
            "model_type": "causal",
            "benchmark_name": "sevenllm_bench",
            "benchmark_path": "/workspace/calibration_data/sevenllm_instruct_subset_manual/",
            "results_dir": "/workspace/results/mod/48",
            "device": "cuda",
            "max_new_tokens": 512,
            "num_samples": 100,
            "cti_subset": null
        },
        "total_items_in_output": 100,
        "items_with_ground_truth": 100,
        "items_missing_ground_truth": 0,
        "refusal_count": 0,
        "valid_processed_count": 100,
        "exact_match_count": 0,
        "refusal_rate": 0.0,
        "exact_match_accuracy": 0.0,
        "average_rouge1_f1": 0.0,
        "average_rouge2_f1": 0.0,
        "average_rougeL_f1": 0.0
    },
    {
        "model_name": "quantized-gptq-4bit",
        "benchmark_name": "sevenllm_bench",
        "timestamp_str": "20250424-043745",
        "outputs_file": "results/mod/48/sevenllm_bench__20250424-043745_outputs.json",
        "metrics_file": "results/mod/48/sevenllm_bench__20250424-043745_metrics.json",
        "run_args": {
            "model_path": "/workspace/models/Phi-3-mini-4k-instruct/quantized-gptq-4bit/",
            "model_type": "causal",
            "benchmark_name": "sevenllm_bench",
            "benchmark_path": "/workspace/calibration_data/sevenllm_instruct_subset_manual/",
            "results_dir": "/workspace/results/mod/48",
            "device": "cuda",
            "max_new_tokens": 512,
            "num_samples": 100,
            "cti_subset": null
        },
        "total_items_in_output": 100,
        "items_with_ground_truth": 100,
        "items_missing_ground_truth": 0,
        "refusal_count": 0,
        "valid_processed_count": 100,
        "exact_match_count": 0,
        "refusal_rate": 0.0,
        "exact_match_accuracy": 0.0,
        "average_rouge1_f1": 0.0,
        "average_rouge2_f1": 0.0,
        "average_rougeL_f1": 0.0
    },
    {
        "model_name": "quantized-gptq-4bit",
        "benchmark_name": "sevenllm_bench",
        "timestamp_str": "20250424-044830",
        "outputs_file": "results/mod/48/sevenllm_bench__20250424-044830_outputs.json",
        "metrics_file": "results/mod/48/sevenllm_bench__20250424-044830_metrics.json",
        "run_args": {
            "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/quantized-gptq-4bit/",
            "model_type": "causal",
            "benchmark_name": "sevenllm_bench",
            "benchmark_path": "/workspace/calibration_data/sevenllm_instruct_subset_manual/",
            "results_dir": "/workspace/results/mod/48",
            "device": "cuda",
            "max_new_tokens": 512,
            "num_samples": 100,
            "cti_subset": null
        },
        "total_items_in_output": 100,
        "items_with_ground_truth": 100,
        "items_missing_ground_truth": 0,
        "refusal_count": 0,
        "valid_processed_count": 100,
        "exact_match_count": 0,
        "refusal_rate": 0.0,
        "exact_match_accuracy": 0.0,
        "average_rouge1_f1": 0.0,
        "average_rouge2_f1": 0.0,
        "average_rougeL_f1": 0.0
    },
    {
        "model_name": "TinyLlama-1.1B-Chat-v1.0-GPTQ",
        "benchmark_name": "sevenllm_bench",
        "timestamp_str": "20250424-081254",
        "outputs_file": "results/mod/48/sevenllm_bench_TinyLlama-1.1B-Chat-v1.0-GPTQ_20250424-081254_outputs.json",
        "metrics_file": "results/mod/48/sevenllm_bench_TinyLlama-1.1B-Chat-v1.0-GPTQ_20250424-081254_metrics.json",
        "run_args": {
            "model_path": "/workspace/models/TinyLlama-1.1B-Chat-v1.0-GPTQ",
            "model_type": "causal",
            "benchmark_name": "sevenllm_bench",
            "benchmark_path": "/workspace/calibration_data/sevenllm_instruct_subset_manual/",
            "results_dir": "/workspace/results/mod/48",
            "device": "cuda",
            "max_new_tokens": 512,
            "num_samples": 100,
            "cti_subset": null
        },
        "total_items_in_output": 100,
        "items_with_ground_truth": 100,
        "items_missing_ground_truth": 0,
        "refusal_count": 0,
        "valid_processed_count": 100,
        "exact_match_count": 0,
        "refusal_rate": 0.0,
        "exact_match_accuracy": 0.0,
        "average_rouge1_f1": 0.0,
        "average_rouge2_f1": 0.0,
        "average_rougeL_f1": 0.0
    },
    {
        "model_name": "Phi-3-mini-4k-instruct-GPTQ",
        "benchmark_name": "sevenllm_bench",
        "timestamp_str": "20250424-114229",
        "outputs_file": "results/mod/48/sevenllm_bench_Phi-3-mini-4k-instruct-GPTQ_20250424-114229_outputs.json",
        "metrics_file": "results/mod/48/sevenllm_bench_Phi-3-mini-4k-instruct-GPTQ_20250424-114229_metrics.json",
        "run_args": {
            "model_path": "/workspace/models/Phi-3-mini-4k-instruct-GPTQ",
            "model_type": "causal",
            "benchmark_name": "sevenllm_bench",
            "benchmark_path": "/workspace/calibration_data/sevenllm_instruct_subset_manual/",
            "results_dir": "/workspace/results/mod/48",
            "device": "cuda",
            "max_new_tokens": 512,
            "num_samples": 100,
            "cti_subset": null
        },
        "total_items_in_output": 100,
        "items_with_ground_truth": 100,
        "items_missing_ground_truth": 0,
        "refusal_count": 0,
        "valid_processed_count": 100,
        "exact_match_count": 0,
        "refusal_rate": 0.0,
        "exact_match_accuracy": 0.0,
        "average_rouge1_f1": 0.0,
        "average_rouge2_f1": 0.0,
        "average_rougeL_f1": 0.0
    },
    {
        "model_name": "Phi-3-mini-4k-instruct-GPTQ",
        "benchmark_name": "sevenllm_bench",
        "timestamp_str": "20250424-114911",
        "outputs_file": "results/mod/48/sevenllm_bench_Phi-3-mini-4k-instruct-GPTQ_20250424-114911_outputs.json",
        "metrics_file": "results/mod/48/sevenllm_bench_Phi-3-mini-4k-instruct-GPTQ_20250424-114911_metrics.json",
        "run_args": {
            "model_path": "/workspace/models/Phi-3-mini-4k-instruct-GPTQ",
            "model_type": "causal",
            "benchmark_name": "sevenllm_bench",
            "benchmark_path": "/workspace/calibration_data/sevenllm_instruct_subset_manual/",
            "results_dir": "/workspace/results/mod/48",
            "device": "cuda",
            "max_new_tokens": 512,
            "num_samples": 100,
            "cti_subset": null
        },
        "total_items_in_output": 100,
        "items_with_ground_truth": 100,
        "items_missing_ground_truth": 0,
        "refusal_count": 0,
        "valid_processed_count": 100,
        "exact_match_count": 0,
        "refusal_rate": 0.0,
        "exact_match_accuracy": 0.0,
        "average_rouge1_f1": 0.0,
        "average_rouge2_f1": 0.0,
        "average_rougeL_f1": 0.0
    },
    {
        "model_name": "Phi-3-mini-4k-instruct-GPTQ",
        "benchmark_name": "sevenllm_bench",
        "timestamp_str": "20250424-122854",
        "outputs_file": "results/mod/48/sevenllm_bench_Phi-3-mini-4k-instruct-GPTQ_20250424-122854_outputs.json",
        "metrics_file": "results/mod/48/sevenllm_bench_Phi-3-mini-4k-instruct-GPTQ_20250424-122854_metrics.json",
        "run_args": {
            "model_path": "/workspace/models/Phi-3-mini-4k-instruct-GPTQ",
            "model_type": "causal",
            "benchmark_name": "sevenllm_bench",
            "benchmark_path": "/workspace/calibration_data/sevenllm_instruct_subset_manual/",
            "results_dir": "/workspace/results/mod/48",
            "device": "cuda",
            "max_new_tokens": 512,
            "num_samples": 100,
            "cti_subset": null,
            "batch_size": 32,
            "trust_remote_code": false
        },
        "total_items_in_output": 100,
        "items_with_ground_truth": 100,
        "items_missing_ground_truth": 0,
        "refusal_count": 0,
        "valid_processed_count": 100,
        "exact_match_count": 0,
        "refusal_rate": 0.0,
        "exact_match_accuracy": 0.0,
        "average_rouge1_f1": 0.0,
        "average_rouge2_f1": 0.0,
        "average_rougeL_f1": 0.0
    },
    {
        "model_name": "Mistral-7B-Instruct-v0.3-GPTQ",
        "benchmark_name": "sevenllm_bench",
        "timestamp_str": "20250424-130142",
        "outputs_file": "results/mod/48/sevenllm_bench_Mistral-7B-Instruct-v0.3-GPTQ_20250424-130142_outputs.json",
        "metrics_file": "results/mod/48/sevenllm_bench_Mistral-7B-Instruct-v0.3-GPTQ_20250424-130142_metrics.json",
        "run_args": {
            "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3-GPTQ",
            "model_type": "causal",
            "benchmark_name": "sevenllm_bench",
            "benchmark_path": "/workspace/calibration_data/sevenllm_instruct_subset_manual/",
            "results_dir": "/workspace/results/mod/48",
            "device": "cuda",
            "max_new_tokens": 512,
            "num_samples": 100,
            "cti_subset": null,
            "batch_size": 32,
            "trust_remote_code": true
        },
        "total_items_in_output": 100,
        "items_with_ground_truth": 100,
        "items_missing_ground_truth": 0,
        "refusal_count": 0,
        "valid_processed_count": 100,
        "exact_match_count": 0,
        "refusal_rate": 0.0,
        "exact_match_accuracy": 0.0,
        "average_rouge1_f1": 0.0,
        "average_rouge2_f1": 0.0,
        "average_rougeL_f1": 0.0
    }
]