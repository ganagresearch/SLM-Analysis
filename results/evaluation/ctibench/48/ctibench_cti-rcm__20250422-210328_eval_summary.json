{
    "model_name": "Mistral-7B-Instruct-v0.3",
    "timestamp": "20250422-210328",
    "input_output_file": "results/bare/48/ctibench_cti-rcm__20250422-210328_outputs.json",
    "input_metrics_file": "results/bare/48/ctibench_cti-rcm__20250422-210328_metrics.json",
    "input_ground_truth_file": "code/analysis/ctibench_ground_truth/cti-rcm_ground_truth.jsonl",
    "model_path": "/workspace/models/Mistral-7B-Instruct-v0.3/",
    "model_type": "causal",
    "benchmark_name": "ctibench",
    "benchmark_path": "/workspace/datasets",
    "results_dir": "/workspace/results/bare/48",
    "device": "cuda",
    "max_new_tokens": 512,
    "num_samples": 100,
    "cti_subset": "cti-rcm",
    "task_type": "rcm",
    "total_items_in_output": 100,
    "items_with_ground_truth": 100,
    "items_missing_ground_truth": 0,
    "items_refused": 0,
    "items_parsing_error": 0,
    "items_processed_for_accuracy": 100,
    "correct_matches": 46,
    "accuracy": 0.46
}