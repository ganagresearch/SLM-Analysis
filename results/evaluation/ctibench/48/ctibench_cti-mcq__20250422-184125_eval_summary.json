{
    "model_name": "Phi-3-mini-4k-instruct",
    "timestamp": "20250422-184125",
    "input_output_file": "results/bare/48/ctibench_cti-mcq__20250422-184125_outputs.json",
    "input_metrics_file": "results/bare/48/ctibench_cti-mcq__20250422-184125_metrics.json",
    "input_ground_truth_file": "code/analysis/ctibench_ground_truth/cti-mcq_ground_truth.jsonl",
    "model_path": "/workspace/models/Phi-3-mini-4k-instruct/",
    "model_type": "causal",
    "benchmark_name": "ctibench",
    "benchmark_path": "/workspace/datasets",
    "results_dir": "/workspace/results/bare/48",
    "device": "cuda",
    "max_new_tokens": 512,
    "num_samples": 100,
    "cti_subset": "cti-mcq",
    "task_type": "mcq",
    "total_items_in_output": 100,
    "items_with_ground_truth": 100,
    "items_missing_ground_truth": 0,
    "items_refused": 0,
    "items_parsing_error": 0,
    "items_processed_for_accuracy": 100,
    "correct_matches": 63,
    "accuracy": 0.63
}