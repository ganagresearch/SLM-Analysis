2025-04-22 17:20:24,711 - INFO - --- Starting Benchmark Automation ---
2025-04-22 17:20:24,711 - INFO - Python Executable: /workspace/testbedvenv/bin/python
2025-04-22 17:20:24,712 - INFO - Evaluation Script: /workspace/code/model_evaluator/evaluate_cli.py
2025-04-22 17:20:24,712 - INFO - Results Directory: /workspace/results/bare/48
2025-04-22 17:20:24,712 - INFO - Error Log File: /workspace/results/bare/48/automation_errors.log
2025-04-22 17:20:24,712 - INFO - Models to run: ['TinyLlama-1.1B-Chat-v1.0', 'Phi-3-mini-4k-instruct', 'Mistral-7B-Instruct-v0.3', 'electra-small-discriminator']
2025-04-22 17:20:24,713 - INFO - Benchmarks to run: [('cyberseceval3_mitre', [None]), ('sevenllm_bench', [None]), ('ctibench', ['cti-mcq', 'cti-vsp', 'cti-rcm'])]
2025-04-22 17:20:24,713 - INFO - Total runs planned: 20
2025-04-22 17:20:24,713 - INFO - 
Run 1/20: Model='TinyLlama-1.1B-Chat-v1.0', Benchmark='cyberseceval3_mitre'
2025-04-22 17:20:24,714 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/TinyLlama-1.1B-Chat-v1.0/ --model-type causal --benchmark-name cyberseceval3_mitre --benchmark-path /workspace/code/PurpleLlama/CybersecurityBenchmarks/datasets/mitre/mitre_benchmark_100_per_category_with_augmentation.json --results-dir /workspace/results/bare/48 --num-samples 100 --max-new-tokens 512
2025-04-22 17:31:48,172 - INFO - SUCCESS: Run 1/20: Model='TinyLlama-1.1B-Chat-v1.0', Benchmark='cyberseceval3_mitre'
2025-04-22 17:31:48,173 - INFO - 
Run 2/20: Model='TinyLlama-1.1B-Chat-v1.0', Benchmark='sevenllm_bench'
2025-04-22 17:31:48,174 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/TinyLlama-1.1B-Chat-v1.0/ --model-type causal --benchmark-name sevenllm_bench --benchmark-path /workspace/calibration_data/sevenllm_instruct_subset_manual/ --results-dir /workspace/results/bare/48 --num-samples 100 --max-new-tokens 512
2025-04-22 17:43:03,387 - INFO - SUCCESS: Run 2/20: Model='TinyLlama-1.1B-Chat-v1.0', Benchmark='sevenllm_bench'
2025-04-22 17:43:03,388 - INFO - 
Run 3/20: Model='TinyLlama-1.1B-Chat-v1.0', Benchmark='ctibench', Subset='cti-mcq'
2025-04-22 17:43:03,389 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/TinyLlama-1.1B-Chat-v1.0/ --model-type causal --benchmark-name ctibench --benchmark-path /workspace/datasets --results-dir /workspace/results/bare/48 --num-samples 100 --cti-subset cti-mcq --max-new-tokens 512
2025-04-22 17:45:23,830 - INFO - SUCCESS: Run 3/20: Model='TinyLlama-1.1B-Chat-v1.0', Benchmark='ctibench', Subset='cti-mcq'
2025-04-22 17:45:23,831 - INFO - 
Run 4/20: Model='TinyLlama-1.1B-Chat-v1.0', Benchmark='ctibench', Subset='cti-vsp'
2025-04-22 17:45:23,832 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/TinyLlama-1.1B-Chat-v1.0/ --model-type causal --benchmark-name ctibench --benchmark-path /workspace/datasets --results-dir /workspace/results/bare/48 --num-samples 100 --cti-subset cti-vsp --max-new-tokens 512
2025-04-22 17:54:11,393 - INFO - SUCCESS: Run 4/20: Model='TinyLlama-1.1B-Chat-v1.0', Benchmark='ctibench', Subset='cti-vsp'
2025-04-22 17:54:11,394 - INFO - 
Run 5/20: Model='TinyLlama-1.1B-Chat-v1.0', Benchmark='ctibench', Subset='cti-rcm'
2025-04-22 17:54:11,395 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/TinyLlama-1.1B-Chat-v1.0/ --model-type causal --benchmark-name ctibench --benchmark-path /workspace/datasets --results-dir /workspace/results/bare/48 --num-samples 100 --cti-subset cti-rcm --max-new-tokens 512
2025-04-22 18:02:45,916 - INFO - SUCCESS: Run 5/20: Model='TinyLlama-1.1B-Chat-v1.0', Benchmark='ctibench', Subset='cti-rcm'
2025-04-22 18:02:45,917 - INFO - 
Run 6/20: Model='Phi-3-mini-4k-instruct', Benchmark='cyberseceval3_mitre'
2025-04-22 18:02:45,918 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/Phi-3-mini-4k-instruct/ --model-type causal --benchmark-name cyberseceval3_mitre --benchmark-path /workspace/code/PurpleLlama/CybersecurityBenchmarks/datasets/mitre/mitre_benchmark_100_per_category_with_augmentation.json --results-dir /workspace/results/bare/48 --num-samples 100 --max-new-tokens 512
2025-04-22 18:21:38,584 - INFO - SUCCESS: Run 6/20: Model='Phi-3-mini-4k-instruct', Benchmark='cyberseceval3_mitre'
2025-04-22 18:21:38,585 - INFO - 
Run 7/20: Model='Phi-3-mini-4k-instruct', Benchmark='sevenllm_bench'
2025-04-22 18:21:38,585 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/Phi-3-mini-4k-instruct/ --model-type causal --benchmark-name sevenllm_bench --benchmark-path /workspace/calibration_data/sevenllm_instruct_subset_manual/ --results-dir /workspace/results/bare/48 --num-samples 100 --max-new-tokens 512
2025-04-22 18:40:41,869 - INFO - SUCCESS: Run 7/20: Model='Phi-3-mini-4k-instruct', Benchmark='sevenllm_bench'
2025-04-22 18:40:41,871 - INFO - 
Run 8/20: Model='Phi-3-mini-4k-instruct', Benchmark='ctibench', Subset='cti-mcq'
2025-04-22 18:40:41,872 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/Phi-3-mini-4k-instruct/ --model-type causal --benchmark-name ctibench --benchmark-path /workspace/datasets --results-dir /workspace/results/bare/48 --num-samples 100 --cti-subset cti-mcq --max-new-tokens 512
2025-04-22 18:42:30,902 - INFO - SUCCESS: Run 8/20: Model='Phi-3-mini-4k-instruct', Benchmark='ctibench', Subset='cti-mcq'
2025-04-22 18:42:30,910 - INFO - 
Run 9/20: Model='Phi-3-mini-4k-instruct', Benchmark='ctibench', Subset='cti-vsp'
2025-04-22 18:42:30,911 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/Phi-3-mini-4k-instruct/ --model-type causal --benchmark-name ctibench --benchmark-path /workspace/datasets --results-dir /workspace/results/bare/48 --num-samples 100 --cti-subset cti-vsp --max-new-tokens 512
2025-04-22 19:04:07,375 - INFO - SUCCESS: Run 9/20: Model='Phi-3-mini-4k-instruct', Benchmark='ctibench', Subset='cti-vsp'
2025-04-22 19:04:07,376 - INFO - 
Run 10/20: Model='Phi-3-mini-4k-instruct', Benchmark='ctibench', Subset='cti-rcm'
2025-04-22 19:04:07,377 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/Phi-3-mini-4k-instruct/ --model-type causal --benchmark-name ctibench --benchmark-path /workspace/datasets --results-dir /workspace/results/bare/48 --num-samples 100 --cti-subset cti-rcm --max-new-tokens 512
2025-04-22 19:12:12,458 - INFO - SUCCESS: Run 10/20: Model='Phi-3-mini-4k-instruct', Benchmark='ctibench', Subset='cti-rcm'
2025-04-22 19:12:12,459 - INFO - 
Run 11/20: Model='Mistral-7B-Instruct-v0.3', Benchmark='cyberseceval3_mitre'
2025-04-22 19:12:12,460 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/Mistral-7B-Instruct-v0.3/ --model-type causal --benchmark-name cyberseceval3_mitre --benchmark-path /workspace/code/PurpleLlama/CybersecurityBenchmarks/datasets/mitre/mitre_benchmark_100_per_category_with_augmentation.json --results-dir /workspace/results/bare/48 --num-samples 100 --max-new-tokens 512
2025-04-22 19:53:26,545 - INFO - SUCCESS: Run 11/20: Model='Mistral-7B-Instruct-v0.3', Benchmark='cyberseceval3_mitre'
2025-04-22 19:53:26,548 - INFO - 
Run 12/20: Model='Mistral-7B-Instruct-v0.3', Benchmark='sevenllm_bench'
2025-04-22 19:53:26,548 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/Mistral-7B-Instruct-v0.3/ --model-type causal --benchmark-name sevenllm_bench --benchmark-path /workspace/calibration_data/sevenllm_instruct_subset_manual/ --results-dir /workspace/results/bare/48 --num-samples 100 --max-new-tokens 512
2025-04-22 20:20:05,238 - INFO - SUCCESS: Run 12/20: Model='Mistral-7B-Instruct-v0.3', Benchmark='sevenllm_bench'
2025-04-22 20:20:05,239 - INFO - 
Run 13/20: Model='Mistral-7B-Instruct-v0.3', Benchmark='ctibench', Subset='cti-mcq'
2025-04-22 20:20:05,240 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/Mistral-7B-Instruct-v0.3/ --model-type causal --benchmark-name ctibench --benchmark-path /workspace/datasets --results-dir /workspace/results/bare/48 --num-samples 100 --cti-subset cti-mcq --max-new-tokens 512
2025-04-22 20:23:22,920 - INFO - SUCCESS: Run 13/20: Model='Mistral-7B-Instruct-v0.3', Benchmark='ctibench', Subset='cti-mcq'
2025-04-22 20:23:22,921 - INFO - 
Run 14/20: Model='Mistral-7B-Instruct-v0.3', Benchmark='ctibench', Subset='cti-vsp'
2025-04-22 20:23:22,922 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/Mistral-7B-Instruct-v0.3/ --model-type causal --benchmark-name ctibench --benchmark-path /workspace/datasets --results-dir /workspace/results/bare/48 --num-samples 100 --cti-subset cti-vsp --max-new-tokens 512
2025-04-22 21:02:31,796 - INFO - SUCCESS: Run 14/20: Model='Mistral-7B-Instruct-v0.3', Benchmark='ctibench', Subset='cti-vsp'
2025-04-22 21:02:31,797 - INFO - 
Run 15/20: Model='Mistral-7B-Instruct-v0.3', Benchmark='ctibench', Subset='cti-rcm'
2025-04-22 21:02:31,798 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/Mistral-7B-Instruct-v0.3/ --model-type causal --benchmark-name ctibench --benchmark-path /workspace/datasets --results-dir /workspace/results/bare/48 --num-samples 100 --cti-subset cti-rcm --max-new-tokens 512
2025-04-22 21:22:32,920 - INFO - SUCCESS: Run 15/20: Model='Mistral-7B-Instruct-v0.3', Benchmark='ctibench', Subset='cti-rcm'
2025-04-22 21:22:32,921 - INFO - 
Run 16/20: Model='electra-small-discriminator', Benchmark='cyberseceval3_mitre'
2025-04-22 21:22:32,922 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/electra-small-discriminator/ --model-type encoder --benchmark-name cyberseceval3_mitre --benchmark-path /workspace/code/PurpleLlama/CybersecurityBenchmarks/datasets/mitre/mitre_benchmark_100_per_category_with_augmentation.json --results-dir /workspace/results/bare/48 --num-samples 100
2025-04-22 21:23:20,379 - INFO - SUCCESS: Run 16/20: Model='electra-small-discriminator', Benchmark='cyberseceval3_mitre'
2025-04-22 21:23:20,381 - INFO - 
Run 17/20: Model='electra-small-discriminator', Benchmark='sevenllm_bench'
2025-04-22 21:23:20,381 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/electra-small-discriminator/ --model-type encoder --benchmark-name sevenllm_bench --benchmark-path /workspace/calibration_data/sevenllm_instruct_subset_manual/ --results-dir /workspace/results/bare/48 --num-samples 100
2025-04-22 21:23:49,960 - INFO - SUCCESS: Run 17/20: Model='electra-small-discriminator', Benchmark='sevenllm_bench'
2025-04-22 21:23:49,961 - INFO - 
Run 18/20: Model='electra-small-discriminator', Benchmark='ctibench', Subset='cti-mcq'
2025-04-22 21:23:49,962 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/electra-small-discriminator/ --model-type encoder --benchmark-name ctibench --benchmark-path /workspace/datasets --results-dir /workspace/results/bare/48 --num-samples 100 --cti-subset cti-mcq
2025-04-22 21:24:23,766 - INFO - SUCCESS: Run 18/20: Model='electra-small-discriminator', Benchmark='ctibench', Subset='cti-mcq'
2025-04-22 21:24:23,767 - INFO - 
Run 19/20: Model='electra-small-discriminator', Benchmark='ctibench', Subset='cti-vsp'
2025-04-22 21:24:23,767 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/electra-small-discriminator/ --model-type encoder --benchmark-name ctibench --benchmark-path /workspace/datasets --results-dir /workspace/results/bare/48 --num-samples 100 --cti-subset cti-vsp
2025-04-22 21:24:57,338 - INFO - SUCCESS: Run 19/20: Model='electra-small-discriminator', Benchmark='ctibench', Subset='cti-vsp'
2025-04-22 21:24:57,339 - INFO - 
Run 20/20: Model='electra-small-discriminator', Benchmark='ctibench', Subset='cti-rcm'
2025-04-22 21:24:57,339 - INFO - Executing command: /workspace/testbedvenv/bin/python /workspace/code/model_evaluator/evaluate_cli.py --model-path /workspace/models/electra-small-discriminator/ --model-type encoder --benchmark-name ctibench --benchmark-path /workspace/datasets --results-dir /workspace/results/bare/48 --num-samples 100 --cti-subset cti-rcm
2025-04-22 21:25:29,218 - INFO - SUCCESS: Run 20/20: Model='electra-small-discriminator', Benchmark='ctibench', Subset='cti-rcm'
2025-04-22 21:25:29,219 - INFO - --- Benchmark Automation Finished ---
